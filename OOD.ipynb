{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phucdt/anaconda3/envs/bio/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/home/phucdt/anaconda3/envs/bio/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as tvt\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from pytorch_ood.dataset.img import Textures\n",
    "from pytorch_ood.detector import OpenMax\n",
    "from pytorch_ood.utils import OODMetrics, ToUnknown\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "torch.manual_seed(1234)\n",
    "device = \"cuda:2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dev set\n",
    "devdf = pd.read_csv(\"xinwang_vocoders/data/voc.v4/protocol.txt\", sep=\" \", header=None)\n",
    "devdf.columns = [\"path\", \"subset\",\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load out-of-distribution set\n",
    "melgan_dir = 'xinwang_vocoders/data/voc.v4/MelGAN'\n",
    "file_list = os.listdir(melgan_dir)\n",
    "\n",
    "# make dataframe for out-of-distribution set\n",
    "outdf = pd.DataFrame()\n",
    "outdf['path'] = file_list\n",
    "outdf['subset'] = 'test'\n",
    "outdf['label'] = 'unknown'\n",
    "outdf['path'] = outdf['path'].apply(lambda x: os.path.join('MelGAN', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>subset</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MelGan/LA_D_3727888.wav</td>\n",
       "      <td>test</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MelGan/LA_T_4565832.wav</td>\n",
       "      <td>test</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MelGan/LA_D_6446182.wav</td>\n",
       "      <td>test</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MelGan/LA_T_1407047.wav</td>\n",
       "      <td>test</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MelGan/LA_D_5542285.wav</td>\n",
       "      <td>test</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      path subset    label\n",
       "0  MelGan/LA_D_3727888.wav   test  unknown\n",
       "1  MelGan/LA_T_4565832.wav   test  unknown\n",
       "2  MelGan/LA_D_6446182.wav   test  unknown\n",
       "3  MelGan/LA_T_1407047.wav   test  unknown\n",
       "4  MelGan/LA_D_5542285.wav   test  unknown"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.concat([devdf[devdf['subset'] == 'dev'], outdf[:2028]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bonafide            2074\n",
       "hn-sinc-nsf         2072\n",
       "waveglow            2062\n",
       "unknown             2028\n",
       "hifigan             2026\n",
       "hn-sinc-nsf-hifi    2023\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to protocol_test.txt\n",
    "testdf['subset'] = 'dev'\n",
    "testdf.to_csv('xinwang_vocoders/data/voc.v4/protocol_test.txt', sep=\" \", header=None, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and data to fit the OpenMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datautils.vocv4 import genList, Dataset_for, Dataset_for_eval\n",
    "from model.wav2vec2_resnet import Model\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "config = yaml.load(open(\"configs/wav2vec2_resnet.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "# load model\n",
    "model = Model(args=config['model'], device=device, emb=False)\n",
    "# load state dict\n",
    "model.load_state_dict(torch.load('out/model_weighted_CCE_100_8_1e-06_wav2vec2_resnet/epoch_31.pth',map_location=device))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of training trials 15383\n"
     ]
    }
   ],
   "source": [
    "# load train data\n",
    "d_label_trn,file_train = genList( dir_meta =  os.path.join('xinwang_vocoders/data/voc.v4/','protocol.txt'),is_train=True,is_eval=False,is_dev=False)\n",
    "print('no. of training trials',len(file_train))\n",
    "train_set=Dataset_for(config,list_IDs = file_train,labels = d_label_trn,base_dir = os.path.join('xinwang_vocoders/data/voc.v4/'),algo=1)\n",
    "train_loader = DataLoader(train_set, batch_size=16,num_workers=8, shuffle=True,drop_last = True)\n",
    "del train_set,d_label_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of validation trials 12285\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "d_label_dev, file_dev = genList(dir_meta = os.path.join('xinwang_vocoders/data/voc.v4/','protocol_test.txt'),is_train=False,is_eval=False, is_dev=True)\n",
    "    \n",
    "print('no. of validation trials',len(file_dev))\n",
    "    \n",
    "dev_set = Dataset_for(config,list_IDs = file_dev,\n",
    "\tlabels = d_label_dev,\n",
    "\tbase_dir = os.path.join('xinwang_vocoders/data/voc.v4/'),algo=1)\n",
    "test_loader = DataLoader(dev_set, batch_size=16,num_workers=8, shuffle=False)\n",
    "# del dev_set,d_label_dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pytorch_ood.detector.openmax.torch.OpenMax at 0x7f6c7dbfcc10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector = OpenMax(model, alpha=5)\n",
    "detector.fit(train_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1759], dtype=torch.float64)\n",
      "tensor([0.1727], dtype=torch.float64)\n",
      "tensor([0.1786], dtype=torch.float64)\n",
      "tensor([0.1750], dtype=torch.float64)\n",
      "tensor([0.1662], dtype=torch.float64)\n",
      "tensor([0.1767], dtype=torch.float64)\n",
      "tensor([0.1696], dtype=torch.float64)\n",
      "tensor([0.1623], dtype=torch.float64)\n",
      "tensor([0.1827], dtype=torch.float64)\n",
      "tensor([0.1751], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    x, y = dev_set[len(dev_set)-i-1]\n",
    "    print(detector.predict(x.unsqueeze(0).to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = OODMetrics()\n",
    "for x, y in test_loader:\n",
    "    score = detector(x.to(device))\n",
    "    # print(score, y)\n",
    "    metrics.update(score, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = metrics.buffer.get('scores')\n",
    "labels = metrics.buffer.get('labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, scores_idx = torch.sort(scores, stable=True)\n",
    "labels = labels[scores_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12286\n"
     ]
    }
   ],
   "source": [
    "precision, recall, threshold = binary_precision_recall_curve(scores, labels)\n",
    "print(len(threshold))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MaxSoftmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional.classification import (\n",
    "    binary_auroc,\n",
    "    binary_precision_recall_curve,\n",
    "    binary_roc,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_ood.detector import MaxSoftmax\n",
    "\n",
    "detector = MaxSoftmax(model)\n",
    "metrics = OODMetrics()\n",
    "for x, y in test_loader:\n",
    "    metrics.update(detector(x.to(device)), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = metrics.buffer.get('scores')\n",
    "labels = metrics.buffer.get('labels')\n",
    "scores, scores_idx = torch.sort(scores, stable=True)\n",
    "labels = labels[scores_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9968, dtype=torch.float64)\n",
      "{'AUROC': 0.996752917766571, 'AUPR-IN': 0.9879894256591797, 'AUPR-OUT': 0.9992644190788269, 'FPR95TPR': 0.007019596174359322}\n"
     ]
    }
   ],
   "source": [
    "auroc = binary_auroc(scores, labels)\n",
    "print(auroc)\n",
    "print(metrics.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_det_curve(target_scores, nontarget_scores):\n",
    "\n",
    "    n_scores = target_scores.size + nontarget_scores.size\n",
    "    all_scores = np.concatenate((target_scores, nontarget_scores))\n",
    "    labels = np.concatenate((np.ones(target_scores.size), np.zeros(nontarget_scores.size)))\n",
    "\n",
    "    # Sort labels based on scores\n",
    "    indices = np.argsort(all_scores, kind='mergesort')\n",
    "    labels = labels[indices]\n",
    "\n",
    "    # Compute false rejection and false acceptance rates\n",
    "    tar_trial_sums = np.cumsum(labels)\n",
    "    nontarget_trial_sums = nontarget_scores.size - (np.arange(1, n_scores + 1) - tar_trial_sums)\n",
    "\n",
    "    frr = np.concatenate((np.atleast_1d(0), tar_trial_sums / target_scores.size))  # false rejection rates\n",
    "    far = np.concatenate((np.atleast_1d(1), nontarget_trial_sums / nontarget_scores.size))  # false acceptance rates\n",
    "    thresholds = np.concatenate((np.atleast_1d(all_scores[indices[0]] - 0.001), all_scores[indices]))  # Thresholds are the sorted scores\n",
    "\n",
    "    return frr, far, thresholds\n",
    "\n",
    "def calculate_confusion_matrix(target_scores, nontarget_scores, threshold):\n",
    "    \"\"\"\n",
    "    Calculate the confusion matrix for a given threshold.\n",
    "    return: tp, tn, fp, fn\n",
    "    \"\"\"\n",
    "    tp = np.sum(target_scores > threshold)\n",
    "    tn = np.sum(nontarget_scores <= threshold)\n",
    "    fn = np.sum(target_scores <= threshold)\n",
    "    fp = np.sum(nontarget_scores > threshold)\n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def compute_eer(target_scores, nontarget_scores):\n",
    "    \"\"\" Returns equal error rate (EER) and the corresponding threshold. \"\"\"\n",
    "    frr, far, thresholds = compute_det_curve(target_scores, nontarget_scores)\n",
    "    abs_diffs = np.abs(frr - far)\n",
    "    min_index = np.argmin(abs_diffs)\n",
    "    eer = np.mean((frr[min_index], far[min_index]))\n",
    "    return eer, thresholds[min_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_scores = scores[labels == 0]\n",
    "unknown_scores = scores[labels == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 1.92%, threshold: -0.9961\n",
      "TP: 1989, TN: 10060, FP: 197, FN: 39\n"
     ]
    }
   ],
   "source": [
    "eer, th = compute_eer(unknown_scores.cpu().numpy(), known_scores.cpu().numpy())\n",
    "tp, tn, fp, fn = calculate_confusion_matrix(unknown_scores.cpu().numpy(), known_scores.cpu().numpy(), th)\n",
    "\n",
    "print(\"EER: {:.2f}%, threshold: {:.4f}\".format(eer * 100, th))\n",
    "print(\"TP: {}, TN: {}, FP: {}, FN: {}\".format(tp, tn, fp, fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9809)\n"
     ]
    }
   ],
   "source": [
    "from torcheval.metrics import BinaryAccuracy\n",
    "metric = BinaryAccuracy(threshold=-0.9961)\n",
    "metric.update(scores, labels)\n",
    "print(metric.compute())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
