{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phucdt/anaconda3/envs/bio/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/home/phucdt/anaconda3/envs/bio/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as tvt\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from pytorch_ood.dataset.img import Textures\n",
    "from pytorch_ood.detector import OpenMax\n",
    "from pytorch_ood.utils import OODMetrics, ToUnknown\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "torch.manual_seed(1234)\n",
    "device = \"cuda:2\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dev set\n",
    "devdf = pd.read_csv(\"xinwang_vocoders/data/voc.v4/protocol.txt\", sep=\" \", header=None)\n",
    "devdf.columns = [\"path\", \"subset\",\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'xinwang_vocoders/data/voc.v4/MelGAN'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# load out-of-distribution set\u001b[39;00m\n\u001b[1;32m      2\u001b[0m melgan_dir \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mxinwang_vocoders/data/voc.v4/MelGAN\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m file_list \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mlistdir(melgan_dir)\n\u001b[1;32m      5\u001b[0m \u001b[39m# make dataframe for out-of-distribution set\u001b[39;00m\n\u001b[1;32m      6\u001b[0m outdf \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'xinwang_vocoders/data/voc.v4/MelGAN'"
     ]
    }
   ],
   "source": [
    "# load out-of-distribution set\n",
    "melgan_dir = 'xinwang_vocoders/data/voc.v4/MelGAN'\n",
    "file_list = os.listdir(melgan_dir)\n",
    "\n",
    "# make dataframe for out-of-distribution set\n",
    "outdf = pd.DataFrame()\n",
    "outdf['path'] = file_list\n",
    "outdf['subset'] = 'test'\n",
    "outdf['label'] = 'unknown'\n",
    "outdf['path'] = outdf['path'].apply(lambda x: os.path.join('MelGAN', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>subset</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MelGan/LA_D_3727888.wav</td>\n",
       "      <td>test</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MelGan/LA_T_4565832.wav</td>\n",
       "      <td>test</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MelGan/LA_D_6446182.wav</td>\n",
       "      <td>test</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MelGan/LA_T_1407047.wav</td>\n",
       "      <td>test</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MelGan/LA_D_5542285.wav</td>\n",
       "      <td>test</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      path subset    label\n",
       "0  MelGan/LA_D_3727888.wav   test  unknown\n",
       "1  MelGan/LA_T_4565832.wav   test  unknown\n",
       "2  MelGan/LA_D_6446182.wav   test  unknown\n",
       "3  MelGan/LA_T_1407047.wav   test  unknown\n",
       "4  MelGan/LA_D_5542285.wav   test  unknown"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.concat([devdf[devdf['subset'] == 'dev'], outdf[:2028]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bonafide            2074\n",
       "hn-sinc-nsf         2072\n",
       "waveglow            2062\n",
       "unknown             2028\n",
       "hifigan             2026\n",
       "hn-sinc-nsf-hifi    2023\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to protocol_test.txt\n",
    "testdf['subset'] = 'dev'\n",
    "testdf.to_csv('xinwang_vocoders/data/voc.v4/protocol_test.txt', sep=\" \", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in_the_wild set\n",
    "protocol = pd.read_csv(\"/dataa/Dataset/cnsl_real_fake_audio/protocols/protocol_in_the_wild.txt\", sep=\" \", header=None)\n",
    "protocol.columns = [\"path\", \"subset\",\"label\"]\n",
    "protocol_bona = protocol[protocol['label'] == 'bonafide']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19963/19963 [03:11<00:00, 104.23it/s]\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(protocol_bona.iterrows(), total=len(protocol_bona)):\n",
    "    path = os.path.join(\"traindata/jul6/\",row['path'])\n",
    "    shutil.copy(path, \"traindata/jul6/in_the_wild_bona/\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and data to fit the OpenMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datautils.vocv4 import genList, Dataset_for, Dataset_for_eval\n",
    "from model.wav2vec2_resnet import Model\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "config = yaml.load(open(\"configs/wav2vec2_resnet.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "# load model\n",
    "model = Model(args=config['model'], device=device, emb=False)\n",
    "# load state dict\n",
    "model.load_state_dict(torch.load('out/model_weighted_CCE_100_8_1e-06_wav2vec2_resnet/epoch_31.pth',map_location=device))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of training trials 15383\n"
     ]
    }
   ],
   "source": [
    "# load train data\n",
    "d_label_trn,file_train = genList( dir_meta =  os.path.join('xinwang_vocoders/data/voc.v4/','protocol.txt'),is_train=True,is_eval=False,is_dev=False)\n",
    "print('no. of training trials',len(file_train))\n",
    "train_set=Dataset_for(config,list_IDs = file_train,labels = d_label_trn,base_dir = os.path.join('xinwang_vocoders/data/voc.v4/'),algo=1)\n",
    "train_loader = DataLoader(train_set, batch_size=8,num_workers=8, shuffle=True,drop_last = True)\n",
    "del train_set,d_label_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of validation trials 12285\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "d_label_dev, file_dev = genList(dir_meta = os.path.join('xinwang_vocoders/data/voc.v4/','protocol_test.txt'),is_train=False,is_eval=False, is_dev=True)\n",
    "    \n",
    "print('no. of validation trials',len(file_dev))\n",
    "    \n",
    "dev_set = Dataset_for(config,list_IDs = file_dev,\n",
    "\tlabels = d_label_dev,\n",
    "\tbase_dir = os.path.join('xinwang_vocoders/data/voc.v4/'),algo=1)\n",
    "test_loader = DataLoader(dev_set, batch_size=8,num_workers=8, shuffle=False)\n",
    "# del dev_set,d_label_dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pytorch_ood.detector.openmax.torch.OpenMax at 0x7f6c7dbfcc10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector = OpenMax(model, alpha=5)\n",
    "detector.fit(train_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = OODMetrics()\n",
    "for x, y in test_loader:\n",
    "    score = detector(x.to(device))\n",
    "    # print(score, y)\n",
    "    metrics.update(score, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = metrics.buffer.get('scores')\n",
    "labels = metrics.buffer.get('labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, scores_idx = torch.sort(scores, stable=True)\n",
    "labels = labels[scores_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12286\n"
     ]
    }
   ],
   "source": [
    "precision, recall, threshold = binary_precision_recall_curve(scores, labels)\n",
    "print(len(threshold))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxSoftmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional.classification import (\n",
    "    binary_auroc,\n",
    "    binary_precision_recall_curve,\n",
    "    binary_roc,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmaxsoftmax\u001b[39;00m \u001b[39mimport\u001b[39;00m MaxSoftmax\n\u001b[0;32m----> 2\u001b[0m detector \u001b[39m=\u001b[39m MaxSoftmax(model)\n\u001b[1;32m      3\u001b[0m metrics \u001b[39m=\u001b[39m OODMetrics()\n\u001b[1;32m      4\u001b[0m preds \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from maxsoftmax import MaxSoftmax\n",
    "detector = MaxSoftmax(model)\n",
    "metrics = OODMetrics()\n",
    "preds = []\n",
    "for x, y in test_loader:\n",
    "    score, pred = detector(x.to(device))\n",
    "    metrics.update(score, y)\n",
    "    # print(pred)\n",
    "    preds.extend(pred.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                   path subset     label  \\\n",
       "0    generated_audio/ljspeech_parallel_wavegan/LJ01...   test     spoof   \n",
       "1    generated_audio/common_voices_prompts_from_con...   test     spoof   \n",
       "2    generated_audio/ljspeech_multi_band_melgan/LJ0...   test     spoof   \n",
       "3    generated_audio/ljspeech_multi_band_melgan/LJ0...   test     spoof   \n",
       "4     generated_audio/ljspeech_waveglow/LJ042-0066.wav   test     spoof   \n",
       "..                                                 ...    ...       ...   \n",
       "995                            LJSpeech/LJ037-0117.wav   test  bonafide   \n",
       "996                            LJSpeech/LJ029-0081.wav   test  bonafide   \n",
       "997                            LJSpeech/LJ001-0121.wav   test  bonafide   \n",
       "998                            LJSpeech/LJ035-0118.wav   test  bonafide   \n",
       "999                            LJSpeech/LJ015-0170.wav   test  bonafide   \n",
       "\n",
       "        score  pred  \n",
       "0   -0.999410     0  \n",
       "1   -0.999962     0  \n",
       "2   -0.999981     0  \n",
       "3   -0.999962     0  \n",
       "4   -0.999152     0  \n",
       "..        ...   ...  \n",
       "995 -0.998158     0  \n",
       "996 -0.999773     0  \n",
       "997 -0.999943     0  \n",
       "998 -0.999618     0  \n",
       "999 -0.999999     0  \n",
       "\n",
       "[1000 rows x 5 columns]>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf = pd.read_csv(\"/dataa/phucdt/vocodetect/testdf_aasist_jul6_balanceweight_59_wavefake.txt\", sep=\" \")\n",
    "testdf.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                   path subset  label  \\\n",
       "0    generated_audio/ljspeech_parallel_wavegan/LJ01...   test      5   \n",
       "1    generated_audio/common_voices_prompts_from_con...   test      5   \n",
       "2    generated_audio/ljspeech_multi_band_melgan/LJ0...   test      5   \n",
       "3    generated_audio/ljspeech_multi_band_melgan/LJ0...   test      5   \n",
       "4     generated_audio/ljspeech_waveglow/LJ042-0066.wav   test      5   \n",
       "..                                                 ...    ...    ...   \n",
       "995                            LJSpeech/LJ037-0117.wav   test      0   \n",
       "996                            LJSpeech/LJ029-0081.wav   test      0   \n",
       "997                            LJSpeech/LJ001-0121.wav   test      0   \n",
       "998                            LJSpeech/LJ035-0118.wav   test      0   \n",
       "999                            LJSpeech/LJ015-0170.wav   test      0   \n",
       "\n",
       "        score  pred  \n",
       "0   -0.999410     0  \n",
       "1   -0.999962     0  \n",
       "2   -0.999981     0  \n",
       "3   -0.999962     0  \n",
       "4   -0.999152     0  \n",
       "..        ...   ...  \n",
       "995 -0.998158     0  \n",
       "996 -0.999773     0  \n",
       "997 -0.999943     0  \n",
       "998 -0.999618     0  \n",
       "999 -0.999999     0  \n",
       "\n",
       "[1000 rows x 5 columns]>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datautils.vocv4 import LABELS\n",
    "testdf['label'] = testdf['label'].apply(lambda x: LABELS[x] if x in LABELS else 5)\n",
    "testdf.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify the prediction based on the threshold\n",
    "def fix_pred(row):\n",
    "    if row['score'] >= -0.99994:\n",
    "        return 5\n",
    "    else:\n",
    "        return row['pred']\n",
    "testdf['pred_fix'] = testdf.apply(fix_pred, axis=1)\n",
    "# testdf.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>subset</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_fix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wav/LA_T_8847275.wav</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.999427</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wav/LA_D_7605047.wav</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.999375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>wav/LA_T_6708956.wav</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.999421</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>wav/LA_D_6509046.wav</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.997738</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>wav/LA_T_7696598.wav</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.997754</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10219</th>\n",
       "      <td>wav/LA_D_6089259.wav</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.998612</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10225</th>\n",
       "      <td>wav/LA_T_6426400.wav</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.998655</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10231</th>\n",
       "      <td>wav/LA_D_7267402.wav</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.998611</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10240</th>\n",
       "      <td>wav/LA_D_3891696.wav</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.998850</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10244</th>\n",
       "      <td>wav/LA_D_8076652.wav</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.998618</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2074 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       path subset  label     score  pred  pred_fix\n",
       "4      wav/LA_T_8847275.wav    dev      0 -0.999427     0         0\n",
       "9      wav/LA_D_7605047.wav    dev      0 -0.999375     0         0\n",
       "10     wav/LA_T_6708956.wav    dev      0 -0.999421     0         0\n",
       "19     wav/LA_D_6509046.wav    dev      0 -0.997738     0         0\n",
       "22     wav/LA_T_7696598.wav    dev      0 -0.997754     0         0\n",
       "...                     ...    ...    ...       ...   ...       ...\n",
       "10219  wav/LA_D_6089259.wav    dev      0 -0.998612     0         0\n",
       "10225  wav/LA_T_6426400.wav    dev      0 -0.998655     0         0\n",
       "10231  wav/LA_D_7267402.wav    dev      0 -0.998611     0         0\n",
       "10240  wav/LA_D_3891696.wav    dev      0 -0.998850     0         0\n",
       "10244  wav/LA_D_8076652.wav    dev      0 -0.998618     0         0\n",
       "\n",
       "[2074 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf[testdf['label']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5070)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[263,   0,   0,   0,   0, 237],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [256,   0,   0,   0,   0, 244]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torcheval.metrics.functional import multiclass_accuracy, multiclass_confusion_matrix\n",
    "# multi-class accuracy\n",
    "input = torch.tensor(testdf['pred_fix'])\n",
    "target = torch.tensor(testdf['label'])\n",
    "print(multiclass_accuracy(input, target))\n",
    "multiclass_confusion_matrix(input, target, num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>subset</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_fix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>LJSpeech/LJ025-0154.wav</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.981259</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>LJSpeech/LJ035-0124.wav</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.999136</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>LJSpeech/LJ005-0213.wav</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.998954</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>LJSpeech/LJ023-0084.wav</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.999749</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>LJSpeech/LJ028-0223.wav</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.999874</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>LJSpeech/LJ010-0054.wav</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.999809</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>LJSpeech/LJ040-0080.wav</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.999070</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>LJSpeech/LJ037-0117.wav</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.998158</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>LJSpeech/LJ029-0081.wav</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.999773</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>LJSpeech/LJ035-0118.wav</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.999618</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        path subset  label     score  pred  pred_fix\n",
       "503  LJSpeech/LJ025-0154.wav   test      0 -0.981259     0         5\n",
       "504  LJSpeech/LJ035-0124.wav   test      0 -0.999136     0         5\n",
       "508  LJSpeech/LJ005-0213.wav   test      0 -0.998954     0         5\n",
       "513  LJSpeech/LJ023-0084.wav   test      0 -0.999749     0         5\n",
       "517  LJSpeech/LJ028-0223.wav   test      0 -0.999874     0         5\n",
       "..                       ...    ...    ...       ...   ...       ...\n",
       "993  LJSpeech/LJ010-0054.wav   test      0 -0.999809     0         5\n",
       "994  LJSpeech/LJ040-0080.wav   test      0 -0.999070     0         5\n",
       "995  LJSpeech/LJ037-0117.wav   test      0 -0.998158     0         5\n",
       "996  LJSpeech/LJ029-0081.wav   test      0 -0.999773     0         5\n",
       "998  LJSpeech/LJ035-0118.wav   test      0 -0.999618     0         5\n",
       "\n",
       "[237 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf[(testdf['pred_fix'] == 5) & (testdf['label'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                   path subset  label  \\\n",
       "0    generated_audio/ljspeech_parallel_wavegan/LJ01...   test      5   \n",
       "1    generated_audio/common_voices_prompts_from_con...   test      5   \n",
       "2    generated_audio/ljspeech_multi_band_melgan/LJ0...   test      5   \n",
       "3    generated_audio/ljspeech_multi_band_melgan/LJ0...   test      5   \n",
       "4     generated_audio/ljspeech_waveglow/LJ042-0066.wav   test      5   \n",
       "..                                                 ...    ...    ...   \n",
       "995                            LJSpeech/LJ037-0117.wav   test      0   \n",
       "996                            LJSpeech/LJ029-0081.wav   test      0   \n",
       "997                            LJSpeech/LJ001-0121.wav   test      0   \n",
       "998                            LJSpeech/LJ035-0118.wav   test      0   \n",
       "999                            LJSpeech/LJ015-0170.wav   test      0   \n",
       "\n",
       "        score  pred  pred_fix  pred_bi  bi_label  \n",
       "0   -0.999410     0         5        1         1  \n",
       "1   -0.999962     0         0        0         1  \n",
       "2   -0.999981     0         0        0         1  \n",
       "3   -0.999962     0         0        0         1  \n",
       "4   -0.999152     0         5        1         1  \n",
       "..        ...   ...       ...      ...       ...  \n",
       "995 -0.998158     0         5        1         0  \n",
       "996 -0.999773     0         5        1         0  \n",
       "997 -0.999943     0         0        0         0  \n",
       "998 -0.999618     0         5        1         0  \n",
       "999 -0.999999     0         0        0         0  \n",
       "\n",
       "[1000 rows x 8 columns]>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# binary accuracy\n",
    "def pred_bi(row):\n",
    "    if row['pred_fix'] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "def label_bi(row):\n",
    "    if row['label'] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "testdf['pred_bi'] = testdf.apply(pred_bi, axis=1)\n",
    "testdf['bi_label'] = testdf.apply(label_bi, axis=1)\n",
    "testdf.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5070)\n",
      "tensor([[263, 237],\n",
      "        [256, 244]])\n"
     ]
    }
   ],
   "source": [
    "from torcheval.metrics.functional import binary_accuracy, binary_confusion_matrix\n",
    "print(binary_accuracy(torch.tensor(testdf['pred_bi']), torch.tensor(testdf['bi_label'])))\n",
    "print(binary_confusion_matrix(torch.tensor(testdf['pred_bi']), torch.tensor(testdf['bi_label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>subset</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_fix</th>\n",
       "      <th>pred_bi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wav/hifigan_LA_T_9219481.wav</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.999566</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>wav/hifigan_LA_T_9203438.wav</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.998440</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wav/hifigan_LA_T_6240107.wav</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.998435</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>wav/hifigan_LA_T_9918657.wav</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.998474</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>wav/hifigan_LA_D_2412960.wav</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.998258</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10220</th>\n",
       "      <td>wav/hifigan_LA_D_3467485.wav</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.998140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10221</th>\n",
       "      <td>wav/hifigan_LA_D_7879955.wav</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.997882</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10238</th>\n",
       "      <td>wav/hifigan_LA_D_6986371.wav</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.998709</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10249</th>\n",
       "      <td>wav/hifigan_LA_D_8899535.wav</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.998937</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10256</th>\n",
       "      <td>wav/hifigan_LA_T_9398797.wav</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.972088</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2026 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               path subset  label     score  pred  pred_fix  \\\n",
       "7      wav/hifigan_LA_T_9219481.wav    dev      1 -0.999566     1         1   \n",
       "11     wav/hifigan_LA_T_9203438.wav    dev      1 -0.998440     1         1   \n",
       "13     wav/hifigan_LA_T_6240107.wav    dev      1 -0.998435     1         1   \n",
       "14     wav/hifigan_LA_T_9918657.wav    dev      1 -0.998474     1         1   \n",
       "16     wav/hifigan_LA_D_2412960.wav    dev      1 -0.998258     1         1   \n",
       "...                             ...    ...    ...       ...   ...       ...   \n",
       "10220  wav/hifigan_LA_D_3467485.wav    dev      1 -0.998140     1         1   \n",
       "10221  wav/hifigan_LA_D_7879955.wav    dev      1 -0.997882     1         1   \n",
       "10238  wav/hifigan_LA_D_6986371.wav    dev      1 -0.998709     1         1   \n",
       "10249  wav/hifigan_LA_D_8899535.wav    dev      1 -0.998937     1         1   \n",
       "10256  wav/hifigan_LA_T_9398797.wav    dev      1 -0.972088     1         5   \n",
       "\n",
       "       pred_bi  \n",
       "7            1  \n",
       "11           1  \n",
       "13           1  \n",
       "14           1  \n",
       "16           1  \n",
       "...        ...  \n",
       "10220        1  \n",
       "10221        1  \n",
       "10238        1  \n",
       "10249        1  \n",
       "10256        1  \n",
       "\n",
       "[2026 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf[(testdf['label'] == 1) & (testdf['pred_bi'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = torch.Tensor(testdf['score'].values)\n",
    "labels = torch.Tensor(testdf['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = metrics.buffer.get('scores')\n",
    "labels = metrics.buffer.get('labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_det_curve(target_scores, nontarget_scores):\n",
    "\n",
    "    n_scores = target_scores.size + nontarget_scores.size\n",
    "    all_scores = np.concatenate((target_scores, nontarget_scores))\n",
    "    labels = np.concatenate((np.ones(target_scores.size), np.zeros(nontarget_scores.size)))\n",
    "\n",
    "    # Sort labels based on scores\n",
    "    indices = np.argsort(all_scores, kind='mergesort')\n",
    "    labels = labels[indices]\n",
    "\n",
    "    # Compute false rejection and false acceptance rates\n",
    "    tar_trial_sums = np.cumsum(labels)\n",
    "    nontarget_trial_sums = nontarget_scores.size - (np.arange(1, n_scores + 1) - tar_trial_sums)\n",
    "\n",
    "    frr = np.concatenate((np.atleast_1d(0), tar_trial_sums / target_scores.size))  # false rejection rates\n",
    "    far = np.concatenate((np.atleast_1d(1), nontarget_trial_sums / nontarget_scores.size))  # false acceptance rates\n",
    "    thresholds = np.concatenate((np.atleast_1d(all_scores[indices[0]] - 0.001), all_scores[indices]))  # Thresholds are the sorted scores\n",
    "\n",
    "    return frr, far, thresholds\n",
    "\n",
    "def calculate_confusion_matrix(target_scores, nontarget_scores, threshold):\n",
    "    \"\"\"\n",
    "    Calculate the confusion matrix for a given threshold.\n",
    "    return: tp, tn, fp, fn\n",
    "    \"\"\"\n",
    "    tp = np.sum(target_scores > threshold)\n",
    "    tn = np.sum(nontarget_scores <= threshold)\n",
    "    fn = np.sum(target_scores <= threshold)\n",
    "    fp = np.sum(nontarget_scores > threshold)\n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def compute_eer(target_scores, nontarget_scores):\n",
    "    \"\"\" Returns equal error rate (EER) and the corresponding threshold. \"\"\"\n",
    "    frr, far, thresholds = compute_det_curve(target_scores, nontarget_scores)\n",
    "    abs_diffs = np.abs(frr - far)\n",
    "    min_index = np.argmin(abs_diffs)\n",
    "    eer = np.mean((frr[min_index], far[min_index]))\n",
    "    return eer, thresholds[min_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_scores = scores[labels != 0]\n",
    "unknown_scores = scores[labels == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 55.59%, threshold: -0.9987\n",
      "TP: 921, TN: 4534, FP: 5677, FN: 1153\n"
     ]
    }
   ],
   "source": [
    "eer, th = compute_eer(unknown_scores.cpu().numpy(), known_scores.cpu().numpy())\n",
    "tp, tn, fp, fn = calculate_confusion_matrix(unknown_scores.cpu().numpy(), known_scores.cpu().numpy(), th)\n",
    "\n",
    "print(\"EER: {:.2f}%, threshold: {:.4f}\".format(eer * 100, th))\n",
    "print(\"TP: {}, TN: {}, FP: {}, FN: {}\".format(tp, tn, fp, fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1796)\n"
     ]
    }
   ],
   "source": [
    "from torcheval.metrics import BinaryAccuracy\n",
    "metric = BinaryAccuracy(threshold=-0.9987)\n",
    "metric.update(scores, labels)\n",
    "print(metric.compute())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 14.00 MiB (GPU 2; 22.19 GiB total capacity; 16.09 GiB already allocated; 12.44 MiB free; 16.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m preds \u001b[39m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m test_loader:\n\u001b[0;32m----> 6\u001b[0m     score, pred \u001b[39m=\u001b[39m detector(x\u001b[39m.\u001b[39;49mto(device))\n\u001b[1;32m      7\u001b[0m     metrics\u001b[39m.\u001b[39mupdate(score, y)\n\u001b[1;32m      8\u001b[0m     preds\u001b[39m.\u001b[39mextend(pred\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m/dataa/phucdt/vocodetect/maxsoftmax.py:42\u001b[0m, in \u001b[0;36mMaxSoftmax.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m     39\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m    Forwards to predict\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/dataa/phucdt/vocodetect/maxsoftmax.py:51\u001b[0m, in \u001b[0;36mMaxSoftmax.predict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[39mraise\u001b[39;00m ModelNotSetException\n\u001b[0;32m---> 51\u001b[0m model_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n\u001b[1;32m     52\u001b[0m max_idx \u001b[39m=\u001b[39m model_out\u001b[39m.\u001b[39msoftmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscore(model_out, t\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt), max_idx\n",
      "File \u001b[0;32m~/anaconda3/envs/bio/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/dataa/phucdt/vocodetect/model/wav2vec2_resnet.py:80\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     79\u001b[0m     \u001b[39m#-------pre-trained Wav2vec model fine tunning ------------------------##\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     x_ssl_feat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mssl_model\u001b[39m.\u001b[39;49mextract_feat(x\u001b[39m.\u001b[39;49msqueeze(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[1;32m     81\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLL(x_ssl_feat) \u001b[39m#(bs,frame_number,feat_out_dim)\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     \u001b[39m# post-processing on front-end features\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     \u001b[39m# x = x.transpose(1, 2)   #(bs,feat_out_dim,frame_number)\u001b[39;00m\n",
      "File \u001b[0;32m/dataa/phucdt/vocodetect/model/wav2vec2_resnet.py:51\u001b[0m, in \u001b[0;36mSSLModel.extract_feat\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m     48\u001b[0m         input_tmp \u001b[39m=\u001b[39m input_data\n\u001b[1;32m     50\u001b[0m     \u001b[39m# [batch, length, dim]\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(input_tmp, mask\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, features_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)[\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     52\u001b[0m     \u001b[39m# print(emb.shape)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[39mreturn\u001b[39;00m emb\n",
      "File \u001b[0;32m~/anaconda3/envs/bio/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/dataa/phucdt/SSL_Anti-spoofing/fairseq-a54021305d6b3c4c5959ac9395135f63202db8f1/fairseq/models/wav2vec/wav2vec2.py:632\u001b[0m, in \u001b[0;36mWav2Vec2Model.forward\u001b[0;34m(self, source, padding_mask, mask, features_only, layer, mask_indices, mask_channel_indices, padding_count)\u001b[0m\n\u001b[1;32m    629\u001b[0m     y \u001b[39m=\u001b[39m unmasked_features\n\u001b[1;32m    630\u001b[0m     mask_indices \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 632\u001b[0m x, layer_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x, padding_mask\u001b[39m=\u001b[39;49mpadding_mask, layer\u001b[39m=\u001b[39;49mlayer)\n\u001b[1;32m    634\u001b[0m \u001b[39mif\u001b[39;00m features_only:\n\u001b[1;32m    635\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m    636\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m: x,\n\u001b[1;32m    637\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpadding_mask\u001b[39m\u001b[39m\"\u001b[39m: padding_mask,\n\u001b[1;32m    638\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m\"\u001b[39m: unmasked_features,\n\u001b[1;32m    639\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlayer_results\u001b[39m\u001b[39m\"\u001b[39m: layer_results,\n\u001b[1;32m    640\u001b[0m     }\n",
      "File \u001b[0;32m~/anaconda3/envs/bio/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/dataa/phucdt/SSL_Anti-spoofing/fairseq-a54021305d6b3c4c5959ac9395135f63202db8f1/fairseq/models/wav2vec/wav2vec2.py:895\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, x, padding_mask, layer)\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, padding_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, layer\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 895\u001b[0m     x, layer_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_features(x, padding_mask, layer)\n\u001b[1;32m    897\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm_first \u001b[39mand\u001b[39;00m layer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    898\u001b[0m         x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(x)\n",
      "File \u001b[0;32m/dataa/phucdt/SSL_Anti-spoofing/fairseq-a54021305d6b3c4c5959ac9395135f63202db8f1/fairseq/models/wav2vec/wav2vec2.py:935\u001b[0m, in \u001b[0;36mTransformerEncoder.extract_features\u001b[0;34m(self, x, padding_mask, tgt_layer)\u001b[0m\n\u001b[1;32m    933\u001b[0m dropout_probability \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandom()\n\u001b[1;32m    934\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39mor\u001b[39;00m (dropout_probability \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayerdrop):\n\u001b[0;32m--> 935\u001b[0m     x, z \u001b[39m=\u001b[39m layer(x, self_attn_padding_mask\u001b[39m=\u001b[39;49mpadding_mask, need_weights\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    936\u001b[0m     \u001b[39mif\u001b[39;00m tgt_layer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[39m# unpad if needed\u001b[39;00m\n\u001b[1;32m    938\u001b[0m         \u001b[39mif\u001b[39;00m pad_length \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/bio/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/dataa/phucdt/SSL_Anti-spoofing/fairseq-a54021305d6b3c4c5959ac9395135f63202db8f1/fairseq/models/wav2vec/wav2vec2.py:1035\u001b[0m, in \u001b[0;36mTransformerSentenceEncoderLayer.forward\u001b[0;34m(self, x, self_attn_mask, self_attn_padding_mask, need_weights, att_args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m residual \u001b[39m=\u001b[39m x\n\u001b[1;32m   1034\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm_first:\n\u001b[0;32m-> 1035\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn_layer_norm(x)\n\u001b[1;32m   1036\u001b[0m     x, attn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_attn(\n\u001b[1;32m   1037\u001b[0m         query\u001b[39m=\u001b[39mx,\n\u001b[1;32m   1038\u001b[0m         key\u001b[39m=\u001b[39mx,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         attn_mask\u001b[39m=\u001b[39mself_attn_mask,\n\u001b[1;32m   1042\u001b[0m     )\n\u001b[1;32m   1043\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/bio/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/bio/lib/python3.9/site-packages/torch/nn/modules/normalization.py:190\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlayer_norm(\n\u001b[1;32m    191\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalized_shape, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps)\n",
      "File \u001b[0;32m~/anaconda3/envs/bio/lib/python3.9/site-packages/torch/nn/functional.py:2515\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2511\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, weight, bias):\n\u001b[1;32m   2512\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2513\u001b[0m         layer_norm, (\u001b[39minput\u001b[39m, weight, bias), \u001b[39minput\u001b[39m, normalized_shape, weight\u001b[39m=\u001b[39mweight, bias\u001b[39m=\u001b[39mbias, eps\u001b[39m=\u001b[39meps\n\u001b[1;32m   2514\u001b[0m     )\n\u001b[0;32m-> 2515\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mlayer_norm(\u001b[39minput\u001b[39;49m, normalized_shape, weight, bias, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 14.00 MiB (GPU 2; 22.19 GiB total capacity; 16.09 GiB already allocated; 12.44 MiB free; 16.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
